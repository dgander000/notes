{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# kNN (k Nearest Neighbors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instance Based Learning   \n",
    "---\n",
    "Previous algorithms used $X$ features to describe $y$, finding a generalized function $f(x)$:\n",
    "\n",
    "$f(x) = wx+b$\n",
    "\n",
    "For instance based learning create a database of all $x, y$ relationships and upon receiving a new value $x$, simply perform a lookup of $x$ to find $y$. \n",
    "\n",
    "$f(x) = \\textrm{lookup}(x)$\n",
    "\n",
    "### Advantages:\n",
    "- remembers (exact recording of the $x$ to $y$ relationship)\n",
    "- fast (does not have to perform learning)\n",
    "- simple (low complexity)\n",
    "\n",
    "### Disadvantages:\n",
    "- No generalization (can't return unseen data)  \n",
    "- Models noise exactly\n",
    "- Overfitting\n",
    "\t- believes data too much\n",
    "\t- what if to x is stored multiple time?  return both y's?  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## kNN Algorithm\n",
    "---\n",
    "Look at a set of nearest neighbors and selects the majority label. \n",
    "\n",
    "### Pseudocode \n",
    "#### 1. Given : \n",
    "- Training Data: $D= \\{ x_i, y_i \\}$\n",
    "- Distance Metric: $d(q, x)$\n",
    "    - Or some similarity metric\n",
    "    - note this is domain knowledge (up to designer)\n",
    "- Number of Neighbors: $k$\n",
    "    - note this is domain knowledge (up to designer)\n",
    "- Query Point: $q$\n",
    "\n",
    "#### 2. Find:\n",
    "- A set of Nearest Neighbors, $NN$, such that they are the $k$ closest to your query point   \n",
    "$NN = \\{ i: d(q, x_i), k_{\\textrm{smallest}} \\} $\n",
    "\n",
    "#### 3. Return:\n",
    "- Classification\n",
    "    - vote of the $y_i \\in NN$, where $y_i$ is the plurality (majority)  \n",
    "        - could do a weighted vote by how far way point is  \n",
    "        - note this is domain knowledge (up to designer)\n",
    "\t- ties - randomly pick, or take one that is most common in data set, or ...  \n",
    "        - note this is domain knowledge (up to designer)\n",
    "\n",
    "- Regression\n",
    "    - mean of the $y_i \\in NN$\n",
    "        - could do a weighted average\n",
    "        - note this is domain knowledge (up to designer)\n",
    "\n",
    "### Domain Knowledge\n",
    "All the possible paramters to change means you can come up with completely different answers depending on the values you choose for those parameters "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computation and Space Complexity (Big-O)\n",
    "---\n",
    "Assuming sorted data\n",
    "\n",
    "| Model | Task Type| Running Time | Space  |\n",
    "| :------ | :------: | :-----: |  :-----: |\n",
    "|  **1-NN** | learning   |  $1$  |   $n$ |\n",
    "|  **1-NN** | query  |  $\\log{n}$  | $1$ |\n",
    "|  **k-NN** | learning  |  $1$  |  $n$  |\n",
    "|  **k-NN** | query  |  $\\log{n} + k$   |  1  |\n",
    "|  **linear reg.** | learning  | $n$ |   $1$ (m, b) |\n",
    "|  **linear reg.** | query  |  $1$  |  $1$  |\n",
    "\n",
    "kNN is a lazy learner - put off any learning unto absolutely has to  \n",
    "linear regression is an eager learner - learns right away   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## kNN Domain Knowledge\n",
    "---\n",
    "Distance metrics  \n",
    "- *Euclidean*: $ d = \\sqrt{(y_2 - y_1)^2 + (x_2 - x_1)^2} $\n",
    "- *Manhattan*: $ d = \\lvert y_2 - y_1 \\rvert + \\lvert x_2 - x_1 \\rvert  $\n",
    "\n",
    "Data (from $y = x_1^2 + x_2$)     \n",
    "\n",
    "| $X$       | $y$ | \n",
    "|:---:\t\t| :---: | \n",
    "|\t1, 6\t|  \t7\t|  \n",
    "|\t2, 4  \t| \t8 \t|\n",
    "|\t3, 7\t| \t16 \t|  \n",
    "|\t6, 8 \t| \t44\t|\t\n",
    "|\t7, 1\t|\t50 \t|  \n",
    "|\t8, 4\t| \t68\t|   \n",
    "\n",
    "query point:\n",
    "$ q = 4, 2 $   \n",
    "\n",
    "Prediction   \n",
    "\n",
    "|  type \t| $k$ \t| $ave$\t|\n",
    "| :------     | :------: | :-----: |\n",
    "| Euclidean   | 1 \t\t |\t  8    |\n",
    "| Euclidean   | 3 \t\t |\t  42   |\n",
    "| Manhattan   | 1 \t\t |\t  29   |\n",
    "| Manhattan   | 3\t\t |\t  35.5 |   \n",
    "\n",
    "Data was from function $y = x_1^2 + x_2$  \n",
    "So for q = 4,2;  y = 18  \n",
    "**kNN did not do well in this case due to its bias**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## kNN Bias\n",
    "---\n",
    "### Preference Bias\n",
    "Why we prefer one hypothesis over another.  Our belief about what makes a good hypothesis.\n",
    "\n",
    "- Locality\n",
    "    - near points are similar to one another\n",
    "\t- this aspect is embedded in the distance function selected\n",
    "\t- good distance functions and bad one - specific to domain\n",
    "\t\n",
    "- Smoothness\n",
    "    - averaging  \n",
    "    - expecting smooth changing data\n",
    "\n",
    "- All features matter equally"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Curse of Dimensionality\n",
    "---\n",
    "<img src=\"../images/curse_of_dimensionality.png\" width=600 align=\"left\"/>   \n",
    "**As the number of features or dimensions grows, the amount of data we need to generalize accurately grows exponentially!**    $O(2^d)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "---\n",
    "- distance metric - $d(x,q)$ - really matters \n",
    "    - If you pick the wrong one you get strange behavior\n",
    "    - Euclidean, Manhattan  - (weighted)  \n",
    "    - Distance function is just a black box (how similar arbitrary things are)  \n",
    "- how you pick $k$ is important\n",
    "    - what if k = n and use a weighted average or some type of regression over region\n",
    "    - **locally weighted regression** - curve fitting  \n",
    "        - locally weighted regression uses nearby or distance-weighted training examples to form a local approximation to f \n",
    "    - can replace average with regression or classification  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO - kNN from scratch\n",
    "https://github.com/xbno/Projects/blob/master/Models_Scratch/KNN%20from%20scratch.ipynb   \n",
    "and locally weighted regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
