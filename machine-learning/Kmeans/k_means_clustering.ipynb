{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K means clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recap\n",
    "---\n",
    "- Supervised Learning\n",
    "    - Function approximation\n",
    "    - Use labeled training data to generalize labels to new instances\n",
    "- Unsupervised Learning\n",
    "    - Data Description\n",
    "    - Make sense out of unlabeled data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Clustering Problem\n",
    "---\n",
    "- Given\n",
    "    - Set of objects X\n",
    "    - Inter-object distances $D(x,y) = D(y,x)$ and $x,y \\in X$\n",
    "- Output\n",
    "    - Partition $P_D(x) = P_D(y)$\n",
    "    - if x and y are in same cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single Linkage Clustering\n",
    "---\n",
    "<img src=\"../images/single_linkage_clustering.png\" width=500 align=\"right\"/>  \n",
    "- Consider each object a cluster (n objects, each object is its own cluster)\n",
    "- Define intercluster distance as the distance between the clostest two points in the two clusters\n",
    "- Merge the two closest clusters\n",
    "- Repeat n-k times to make n clusters\n",
    "- Run time is $O(n^3)$\n",
    "- Can make strange clusters as it walks around to find shortest distances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K Means Clustering\n",
    "---\n",
    "- pick k cernters (at random) (center does not have to be a point in the collection of objects)\n",
    "- each center \"claims\" its closest points\n",
    "- recompute the centers by averaging the clustered points\n",
    "- repeat until convergence\n",
    "- K means is like hill climbing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K Means as optimization\n",
    "---\n",
    "- configurations: center, P (partition, cluster)\n",
    "- scores: $E(P, center) = \\sum_x \\left\\| center_{P(x)} - x \\right\\|^2$\n",
    "- neighborhood: $p, center = \\{(p^{'}, center)\\} \\cup \\{(p, center^{'})\\}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K Means in Euclidian Space\n",
    "---\n",
    "<img src=\"../images/kmeans_euclidean.png\" width=600 align=\"left\"/>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Properties of K-means clustering\n",
    "---\n",
    "- each iteration polynomial: $O(kn)$\n",
    "- finite (exponential) iterations: $O(k^n)$\n",
    "- error decreases (if ties broken consistently) (with one exception - when things stay same)\n",
    "- can get stuck\n",
    "    - for example k = 3\n",
    "    - if randomly pick two points close to each other in same cluster, could get stuck in local optima\n",
    "    - could use random restarts to help fix this"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Soft Clustering\n",
    "---\n",
    "Lean in probability theory.  Probabilistically from one of many clusters.   \n",
    "\n",
    "Assume the data was generated by:  \n",
    "1. Select one of K Gaussians (fixed known variance) uniformily\n",
    "2. Sample $x_i$ from that Gaussian\n",
    "3. Repeat n times\n",
    "\n",
    "Task: find a hypothesis $h = <\\mu_1, ...., \\mu_k>$ that maximizes the probability of the data ML   \n",
    "\n",
    "**Maximum Likelihood Gaussian**   \n",
    "The ML mean of the Gaussina $\\mu$ is the mean of the data.   \n",
    "\n",
    "What if K of them?  Add hidden variables.    \n",
    "$<X, Z_1, Z_2, .... , Z_k>$  Z's are indicator variable for which cluster it came from"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expectation Maximization (EM)\n",
    "---\n",
    "- move back and forth between two probabilistic calculations\n",
    "- Expectation\n",
    "- Maximization\n",
    "- move back and forth between soft clustering (expectation) and computing means for the soft cluster (maximization)\n",
    "- $E[Z_{ij}]$ likelihood data element i comes from cluster j\n",
    "    - use Bayes rule\n",
    "    - probability data element i was produced by cluster j (normalize)\n",
    "- $\\mu_j$ average $x_i$'s within cluster j what's the likelihood it came from cluster j (normalize)\n",
    "- k-means if cluster assignments use argmax\n",
    "\n",
    "\n",
    "**NOTE: left summation should be with respect to variable j**\n",
    "<img src=\"../images/expectation_maximization.png\" width=600 align=\"left\"/>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Properties of EM\n",
    "---\n",
    "- monotonically non-decreasing likelihood (not getting worse on each step)\n",
    "- does not converge (practically does)\n",
    "- will not diverge\n",
    "- can get stuck (random restart)\n",
    "- works with any distribution (if E, M solvable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering Properties\n",
    "---\n",
    "clustering algorithm takes as set of distance (D) and maps them to clusters (partitions)   \n",
    "\n",
    "$P_D \\leftarrow$ clustering scheme  \n",
    "- Richness:  For any assignemnt of objects to clusters, there is some distance matrix D such that clustering $\\forall C, \\exists_D,  P_D = C $\n",
    "- Scale-invariance:  Scaling distances by a positive value does not change the clustering \n",
    "- Consistency:  Shrinking intra cluster distances and expanding intercluster distances does not change the clustering  \n",
    "\n",
    "**Impossibility Theorem**  \n",
    "No clustering scheme can achieve all three (richness, scale invariance, consistency)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
