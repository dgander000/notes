{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Randomized Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization\n",
    "---\n",
    "- Input space $X$\n",
    "- Objective function $f:x \\rightarrow \\mathbb{R}$\n",
    "    - fitness function\n",
    "    - maps inputs to score\n",
    "- Goal:\n",
    "    - Find $x^* \\in X$ such that $f(x^*)=max_x f(x)$\n",
    "- Optimization helps:\n",
    "    - Find the best process\n",
    "    - Find the best route\n",
    "    - Find the root (where it crosses origin)\n",
    "    - neural network find weights that minimize error\n",
    "    - optimize structure of decision tree\n",
    "    - Find the best parameters of learning algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization Approaches\n",
    "---\n",
    "- Generate and test: small input space, complex functions\n",
    "- Calculus: function has derivative, solvable derivative = 0\n",
    "- Newton's method: function has a derivative, iteratively improve, just single optima   \n",
    "\n",
    "\n",
    "- What if assumptions don't hold?\n",
    "    - big input space\n",
    "    - complex function\n",
    "    - no derivative (or hard to find)\n",
    "    - many local optima\n",
    "    \n",
    "In these cases use Randomized Optimization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hill Climbing\n",
    "---\n",
    "<img src=\"../images/hill_climbing.jpeg\" width=500 align=\"right\"/>  \n",
    "\n",
    "N: neighborhood   \n",
    "\n",
    "- Guess $x \\in X$\n",
    "- Repeat:\n",
    "    - Let neighbor $n^* = argmax_{n \\in N(x)} f(n)$\n",
    "        - find neighbor with largest function value\n",
    "    - if $f(n) > f(x): x=n$\n",
    "        - if that neighbor has a higher function value move to that point \n",
    "    - else: stop   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Restart Hill Climbing\n",
    "---\n",
    "- Once local optimum reached, try again starting from randomly chosen x\n",
    "- Advantages\n",
    "    - multiple tries to find good starting place\n",
    "    - not much more expensive (constant factor)\n",
    "- If there is only one optima, doing random restart will keep giving the same answer\n",
    "- Randomized Hill Climbing may not do better than evaluating all the space in the worst case, but it won’t be worse  \n",
    "- May only be a 'sliver' of the space to find global optimum (basin of attraction).  Bigger basin results in better performance.  If too small could be needle in hay stack."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulated Annealing\n",
    "---\n",
    "- Don't always improve (exploit) - Sometimes you need to search (explore)\n",
    "- Repeated heating and cooling strengthes the blade\n",
    "\n",
    "### Annealing Algorithm\n",
    "- For a finite set of iterations:   \n",
    "    1. Sample new point $x_t$ in $N(x)$\n",
    "    2. Jump to new sample with probability given by an acceptable probability function $P(x, x_t, T)$  (move to new $x_t$ probabilistically)\n",
    "    3. Decrease temperature T > 0\n",
    "        - $P(x,x_t,T)$ = \n",
    "            - 1  if  $f(x_t) \\geq f(x)$\n",
    "            - $e^{\\frac{f(x_t)-f(x)}{T}}$, otherwise (look at fitness difference the two) \n",
    "                 - bit T gives us close to $e^0$ or 1 (likely to jump to new x)\n",
    "                 - small T $\\rightarrow e^{\\infty}$ (only hill climb)  \n",
    "        - **Decrease T slowly** to give the algorithm a chance to find global minima basin\n",
    "            \n",
    "            \n",
    "### Properties of Simulated Annealing   \n",
    "$T \\rightarrow 0$: like hill climbing   \n",
    "$T \\rightarrow \\infty$: random walk     \n",
    "\n",
    "Probability of ending at any point x:   \n",
    "$P_r($ending at x$) = \\frac{e^{\\frac{f(x)}{T}}}{Z_T}$   \n",
    "\n",
    "- Most likely to be in places of high fitness\n",
    "- Decreasing T puts all the weight on f(x) and eventually, pushes the probability to its maximum\n",
    "- However, we need to decrease T slowly to avoid ending up in a local minima\n",
    "- This is called Boltzmann Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Genetic Algorithms\n",
    "---\n",
    "<img src=\"../images/genetic_algorithms.jpeg\" width=500 align=\"right\"/>   \n",
    "\n",
    "- Population of individuals (input points)\n",
    "- Mutation: local search N(x)\n",
    "- Crossover: combine points to hopefully create something better (population holds information)\n",
    "- Generations: iterations of improvements   \n",
    "\n",
    "\n",
    "\n",
    "- Genetic Algorithms perform a randomized, parallel, hill-climbing search for the hypotheses that optimizes a predefined fitness function.\n",
    "- The algorithm operates by iteratively updating a pool of hypotheses, called the population. On each iteration, all members of the population are evaluated according to the fitness function (A predefined numerical measure for the problem). A new population is then generated by probabilistically selecting the most fit individuals from the current population."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Genetic Algorithm Skeleton\n",
    "---\n",
    "- $P_o$ = initial population of size K   \n",
    "- Repeat until converged:   \n",
    "    - compute fitness of all $x \\in P_t$\n",
    "    - select 'most fit' individuals (top half, weighted probability)  \n",
    "    - pair up individuals, replacing \"least fit\" individuals via crossover/mutation\n",
    "\n",
    "\n",
    "- More detail:\n",
    "    - Initialize population: generate an initial hypotheses population $P_t$ of size K, where t indicates the $t^{th}$ generation.\n",
    "    - Evaluate: compute fitness for all $h \\in P_t$\n",
    "    - Create a new generation $P_{t+1}$:\n",
    "        1. Select “most fit” individuals according to the fitness function:    \n",
    "        → Truncation Selection: We take the top half of the population in terms of their scores and declare them to be the most fit.   \n",
    "        → Roulette Wheel Selection: We select individuals at random, but we give the higher\n",
    "        scoring individuals a higher probability to be selected (similar to having a temperature parameter close to ∞).   \n",
    "        $P_r(h_i) = \\frac{Fitness(h_i)}{\\sum_{h_j \\in P_0} Fitness(h_j)}$   \n",
    "        2. Crossover: Probabilistically select pairs of hypotheses from $P_0$ according to $P_r (h_i)$. For each pair, produce an offspring by applying the crossover operator (Copying selected bits from each parent).\n",
    "        3. Mutate: Choose a percentage of the members of $P_0$ with uniform probability. For each, invert one randomly selected bit in its representation.\n",
    "        4. Update $P_t ← P_{t+1}$\n",
    "        5. Evaluate: Compute fitness for all $h \\in P$\n",
    "        6. Repeat till converge.   \n",
    "        \n",
    "        \n",
    "- Genetic Algorithms is less likely to fall into a local minima, because it moves abruptly, replacing parents with offspring that might be radically different. As opposed to Gradient Descent which moves smoothly from one hypothesis to another that is very similar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MIMIC\n",
    "---\n",
    "### Finding Optima by Estimating Probability Densities  \n",
    "- Directly model probabilty distribution  \n",
    "- Successively Refine Model\n",
    "    - Convey Structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problems with Randomized Optimization Algorithms:\n",
    "- There’s no structure or learning. You start with a point and end up with a point that is closer to the global optima.\n",
    "    - only points, no structure\n",
    "- It’s not clear what kind of probability distribution we’re dealing with.\n",
    "    - unclear probability distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probability Model\n",
    "Directly model probability distribution and successively refine the model, will end up with structure.   \n",
    "\n",
    "$P^{\\theta_t}(x)$ = \n",
    "- $\\dfrac{1}{z_{\\theta}}$, if $f(x) \\geq 0$\n",
    "- $0$ otherwise  \n",
    "\n",
    "\n",
    "This probability is uniform over all values of x whose fitness is above some threshold $\\theta$.    \n",
    "\n",
    "\n",
    "$P^{\\theta_{min}}(x)$ = uniform   \n",
    "$P^{\\theta_{max}}(x)$ = optima "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pseudo Code\n",
    "---\n",
    "- Generate samples from probability distribution $P^{θ_t}(x) \\rightarrow$ Generate population\n",
    "- Set $\\theta_{t+1}$ to $n_{th}$ percentile\n",
    "- Retain only those samples such that $f(x) \\geq \\theta_{t+1} \\rightarrow$ Retain fittest\n",
    "- Estimate $P^{\\theta_{t+1}}(x) \\rightarrow$ Estimate a new distribution\n",
    "- Repeat\n",
    "\n",
    "\n",
    "- More detail:\n",
    "    1. We have some threshold θ.\n",
    "    2. We generate a probability distribution that is uniform over all points that have a fitness value ≥ θ.\n",
    "        - This means we generate all the points whose fitness is at least as good as $\\theta$.\n",
    "    3. Take from those the points whose fitness is much higher than θ (Maybe highest 50%)\n",
    "    4. Keep repeating till you reach $\\theta_{max}$.\n",
    "- This way helps us retain the structure from time step to time step.\n",
    "- This should work as intended if:\n",
    "    - We can estimate $P^{\\theta_{t+1}}(x)$ given a finite set of data.\n",
    "    - $P^{\\theta_t}(x) \\approx P^{\\theta_{t+1}}(x)$. That is, when it generates $P^{\\theta_t}(x)$, it also gives samples for the next distribution $P^{\\theta_{t+1}}(x)$, because both distributions are relatively close.\n",
    "- This will eventually lead to $\\theta_{max}$, which convey the global optima."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimating Distributions\n",
    "--- \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
