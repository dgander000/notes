{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Q[(462, 4]: -11.374402515013\nQ[(398, 3]: 4.348907000000002\nQ[(253, 0]: -0.5856821172999982\nQ[(377, 1]: 9.683000000000002\nQ[(83, 5]: -13.996845490100029\n\n\nQ[(123,0)]: -1.5271139055699985\nQ[(402,4)]: -8.539646796999998\nQ[(454,3)]: -3.8232660371605287\nQ[(239,5)]: -1.2852999999999977\nQ[(51,5)]: -12.82326603716053\nQ[(139,4)]: -3.0567699999999975\nQ[(276,0)]: 4.348907000000002\nQ[(241,5)]: -12.136962263511698\nQ[(384,3)]: -3.1369622635116987\nQ[(449,4)]: -13.440939433444477\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "env = gym.make('Taxi-v3')\n",
    "\n",
    "\n",
    "# Q-function\n",
    "# initial_Q = 0.\n",
    "from collections import defaultdict\n",
    "Q = defaultdict(lambda : 0.) # Q-function\n",
    "n = defaultdict(lambda : 1.) # number of visits\n",
    "\n",
    "\n",
    "# Extra\n",
    "actionspace = range(env.action_space.n)\n",
    "greedy_action = lambda s : max(actionspace, key=lambda a : Q[(s,a)])\n",
    "max_q = lambda sp : max([Q[(sp,a)] for a in actionspace])\n",
    "import random\n",
    "epsilon = 0.1\n",
    "gamma = 0.9\n",
    "\n",
    "\n",
    "# Simulation\n",
    "episodescores = []\n",
    "for episode in range(100000):\n",
    "    nextstate = env.reset()\n",
    "    currentscore = 0.\n",
    "    for _ in range(1000):\n",
    "        state = nextstate\n",
    "\n",
    "        # Epsilon-Greedy\n",
    "        if epsilon > random.random() :\n",
    "            action = env.action_space.sample()\n",
    "        else :\n",
    "            action = greedy_action(state)\n",
    "\n",
    "        nextstate, reward, done, info = env.step(action)\n",
    "        currentscore += reward\n",
    "\n",
    "        # Q-learning\n",
    "        if done :\n",
    "            Q[(state,action)] = Q[(state,action)] + 1./n[(state,action)] * ( reward - Q[(state,action)] )\n",
    "            break\n",
    "        else :\n",
    "            Q[(state,action)] = Q[(state,action)] + 1./n[(state,action)] * ( reward + gamma * max_q(nextstate) - Q[(state,action)] )\n",
    "\n",
    "    episodescores.append(currentscore)\n",
    "\n",
    "\n",
    "print('Q[(462, 4]:', Q[(462, 4)])\n",
    "print('Q[(398, 3]:', Q[(398, 3)])\n",
    "print('Q[(253, 0]:', Q[(253, 0)])\n",
    "print('Q[(377, 1]:', Q[(377, 1)])\n",
    "print('Q[(83, 5]:', Q[(83, 5)])\n",
    "print('\\n')\n",
    "print('Q[(123,0)]:', Q[(123,0)])\n",
    "print('Q[(402,4)]:', Q[(402,4)])\n",
    "print('Q[(454,3)]:', Q[(454,3)])\n",
    "print('Q[(239,5)]:', Q[(239,5)])\n",
    "print('Q[(51,5)]:', Q[(51,5)])\n",
    "print('Q[(139,4)]:', Q[(139,4)])\n",
    "print('Q[(276,0)]:', Q[(276,0)])\n",
    "print('Q[(241,5)]:', Q[(241,5)])\n",
    "print('Q[(384,3)]:', Q[(384,3)])\n",
    "print('Q[(449,4)]:', Q[(449,4)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}